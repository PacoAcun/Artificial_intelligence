{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# # 1: Carga y preprocesamiento del dataset MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape imágenes: torch.Size([64, 1, 28, 28])\n",
            "Shape labels: torch.Size([64])\n",
            "Tipo imágenes: torch.float32\n",
            "Rango de valores: -0.4242 a 2.8215\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from typing import Tuple, Dict, Any\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Definimos la transformación:\n",
        "# - Convertir las imágenes a tensores (ToTensor)\n",
        "# - Normalizar usando la media y desviación estándar de MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Cargar dataset de entrenamiento\n",
        "train_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# Cargar dataset de prueba\n",
        "test_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# DataLoaders para manejar batches\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1000,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Verificamos dimensiones y tipo de dato de un batch\n",
        "images, labels = next(iter(train_loader))\n",
        "print(f\"Shape imágenes: {images.shape}\")\n",
        "print(f\"Shape labels: {labels.shape}\")\n",
        "print(f\"Tipo imágenes: {images.dtype}\")\n",
        "print(f\"Rango de valores: {images.min().item():.4f} a {images.max().item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# # 2: Construcción del Modelo MLP (784 -> ... -> 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n",
            "MLP(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Parámetros totales: 203,530\n",
            "Shape de entrada: torch.Size([64, 1, 28, 28])\n",
            "Shape de salida: torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    MLP para MNIST:\n",
        "    - Entrada: 1x28x28 -> se aplana a 784\n",
        "    - Salida: 10 logits (clases 0..9)\n",
        "    - Por defecto: 1 capa oculta de 256 neuronas + ReLU + Dropout ligero\n",
        "      (podemos variar esto en la parte de tuning)\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_layers=(256,), dropout=0.1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_features = 28 * 28  # 784\n",
        "\n",
        "        # Construcción dinámica de capas ocultas\n",
        "        for h in hidden_layers:\n",
        "            layers.append(nn.Linear(in_features, h))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            if dropout and dropout > 0:\n",
        "                layers.append(nn.Dropout(p=dropout))\n",
        "            in_features = h\n",
        "\n",
        "        # Capa de salida a 10 clases\n",
        "        layers.append(nn.Linear(in_features, 10))\n",
        "\n",
        "        # Secuencia\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, 1, 28, 28)\n",
        "        x = torch.flatten(x, start_dim=1)  # -> (batch, 784)\n",
        "        logits = self.net(x)               # -> (batch, 10)\n",
        "        return logits\n",
        "\n",
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Instanciamos el modelo (config base: una capa oculta de 256)\n",
        "model = MLP(hidden_layers=(256,), dropout=0.1).to(device)\n",
        "print(model)\n",
        "print(f\"Parámetros totales: {count_params(model):,}\")\n",
        "\n",
        "# Sanity check: pasar un batch por el modelo y revisar formas\n",
        "# (reutiliza train_loader de la Parte 1)\n",
        "images, labels = next(iter(train_loader))\n",
        "images = images.to(device)\n",
        "with torch.no_grad():\n",
        "    logits = model(images)\n",
        "print(\"Shape de entrada:\", images.shape)     # (batch, 1, 28, 28)\n",
        "print(\"Shape de salida:\", logits.shape)      # (batch, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# # 3: Tres configuraciones y utilidades de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# ---------- Semillas para reproducibilidad ----------\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ---------- Transform y datasets (reaprovecha Parte 1) ----------\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# ---------- MLP con activación configurable ----------\n",
        "def get_activation(name: str):\n",
        "    name = name.lower()\n",
        "    if name == \"relu\":\n",
        "        return lambda: nn.ReLU(inplace=True)\n",
        "    if name == \"tanh\":\n",
        "        return lambda: nn.Tanh()\n",
        "    if name in (\"leakyrelu\", \"leaky_relu\", \"lrelu\"):\n",
        "        return lambda: nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
        "    raise ValueError(f\"Activación no soportada: {name}\")\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, hidden_layers=(256,), activation=\"relu\", dropout=0.1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_features = 28 * 28\n",
        "        act_factory = get_activation(activation)\n",
        "\n",
        "        for h in hidden_layers:\n",
        "            layers.append(nn.Linear(in_features, h))\n",
        "            layers.append(act_factory())  # creamos una nueva instancia de activación\n",
        "            if dropout and dropout > 0:\n",
        "                layers.append(nn.Dropout(p=dropout))\n",
        "            in_features = h\n",
        "\n",
        "        layers.append(nn.Linear(in_features, 10))  # logits\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.net(x)\n",
        "\n",
        "# ---------- Entrenamiento / evaluación ----------\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device, dtype=torch.long)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += x.size(0)\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device, dtype=torch.long)\n",
        "\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += x.size(0)\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "def run_experiment(cfg: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    # DataLoaders en modo seguro\n",
        "    use_cuda = (device.type == \"cuda\")\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=cfg[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=0,                      # <- evita multiprocessing\n",
        "        pin_memory=use_cuda,                # <- solo si hay CUDA\n",
        "        persistent_workers=False\n",
        "    )\n",
        "    test_loader  = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=1000,\n",
        "        shuffle=False,\n",
        "        num_workers=0,                      # <- evita multiprocessing\n",
        "        pin_memory=use_cuda,\n",
        "        persistent_workers=False\n",
        "    )\n",
        "\n",
        "    # Modelo\n",
        "    model = MLP(hidden_layers=cfg[\"hidden_layers\"],\n",
        "                activation=cfg[\"activation\"],\n",
        "                dropout=cfg[\"dropout\"]).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if cfg.get(\"optimizer\", \"adamw\").lower() == \"adamw\":\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg.get(\"weight_decay\", 0.0))\n",
        "    else:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=cfg[\"lr\"])\n",
        "\n",
        "    history = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
        "    start = time.time()\n",
        "    for epoch in range(1, cfg[\"epochs\"] + 1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        te_loss, te_acc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "        history[\"train_loss\"].append(tr_loss)\n",
        "        history[\"train_acc\"].append(tr_acc)\n",
        "        history[\"test_loss\"].append(te_loss)\n",
        "        history[\"test_acc\"].append(te_acc)\n",
        "        print(f'[ {cfg[\"id\"]} ] Epoch {epoch:02d}/{cfg[\"epochs\"]} | '\n",
        "              f'Train Loss: {tr_loss:.4f} Acc: {tr_acc:.4f} | '\n",
        "              f'Test  Loss: {te_loss:.4f} Acc: {te_acc:.4f}')\n",
        "\n",
        "        # Limpieza ocasional (útil si hay poco VRAM)\n",
        "        if use_cuda and (epoch % 2 == 0):\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    result = {\n",
        "        \"id\": cfg[\"id\"],\n",
        "        \"final_test_acc\": history[\"test_acc\"][-1],\n",
        "        \"final_test_loss\": history[\"test_loss\"][-1],\n",
        "        \"params\": sum(p.numel() for p in model.parameters()),\n",
        "        \"elapsed_sec\": elapsed,\n",
        "        \"history\": history,\n",
        "        \"cfg\": cfg\n",
        "    }\n",
        "\n",
        "    # Limpieza explícita antes de salir\n",
        "    del model, train_loader, test_loader, optimizer, criterion\n",
        "    if use_cuda:\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejecutar experimentos A, B, C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Iniciando experimento: A_baseline\n",
            "================================================================================\n",
            "[ A_baseline ] Epoch 01/5 | Train Loss: 0.2384 Acc: 0.9294 | Test  Loss: 0.1193 Acc: 0.9636\n",
            "[ A_baseline ] Epoch 02/5 | Train Loss: 0.1066 Acc: 0.9676 | Test  Loss: 0.0854 Acc: 0.9715\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIniciando experimento: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     res = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     results.append(res)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Ranking simple por accuracy de test (desc)\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 123\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m    121\u001b[39m start = time.time()\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, cfg[\u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     tr_loss, tr_acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m     te_loss, te_acc = evaluate(model, test_loader, criterion, device)\n\u001b[32m    126\u001b[39m     history[\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m].append(tr_loss)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     55\u001b[39m model.train()\n\u001b[32m     56\u001b[39m running_loss, correct, total = \u001b[32m0.0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paco\\miniconda3\\envs\\AI\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paco\\miniconda3\\envs\\AI\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paco\\miniconda3\\envs\\AI\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paco\\miniconda3\\envs\\AI\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = _Image_fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paco\\miniconda3\\envs\\AI\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paco\\miniconda3\\envs\\AI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paco\\miniconda3\\envs\\AI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paco\\miniconda3\\envs\\AI\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[39m, in \u001b[36mNormalize.forward\u001b[39m\u001b[34m(self, tensor)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) -> Tensor:\n\u001b[32m    270\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[33;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m \u001b[33;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paco\\miniconda3\\envs\\AI\\Lib\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch.Tensor):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paco\\miniconda3\\envs\\AI\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:917\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    912\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    913\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected tensor to be a tensor image of size (..., C, H, W). Got tensor.size() = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    914\u001b[39m     )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     tensor = \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m dtype = tensor.dtype\n\u001b[32m    920\u001b[39m mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "configs = [\n",
        "    {\n",
        "        \"id\": \"A_baseline\",\n",
        "        \"hidden_layers\": (256,),\n",
        "        \"activation\": \"relu\",\n",
        "        \"dropout\": 0.10,\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": 1e-3,\n",
        "        \"batch_size\": 64,\n",
        "        \"epochs\": 5,\n",
        "        \"weight_decay\": 0.0\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"B_deeper_tanh\",\n",
        "        \"hidden_layers\": (512, 256),\n",
        "        \"activation\": \"tanh\",\n",
        "        \"dropout\": 0.20,\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": 5e-4,\n",
        "        \"batch_size\": 128,\n",
        "        \"epochs\": 8,\n",
        "        \"weight_decay\": 0.0\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"C_wide_lrelu_wd\",\n",
        "        \"hidden_layers\": (512, 512, 256),\n",
        "        \"activation\": \"leakyrelu\",\n",
        "        \"dropout\": 0.30,\n",
        "        \"optimizer\": \"adamw\",\n",
        "        \"lr\": 7e-4,\n",
        "        \"batch_size\": 256,\n",
        "        \"epochs\": 10,\n",
        "        \"weight_decay\": 1e-4\n",
        "    }\n",
        "]\n",
        "\n",
        "results = []\n",
        "for cfg in configs:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Iniciando experimento: {cfg['id']}\")\n",
        "    print(\"=\"*80)\n",
        "    res = run_experiment(cfg)\n",
        "    results.append(res)\n",
        "\n",
        "# Ranking simple por accuracy de test (desc)\n",
        "results_sorted = sorted(results, key=lambda r: r[\"final_test_acc\"], reverse=True)\n",
        "print(\"\\n\" + \"#\"*80)\n",
        "print(\"RANKING (mejor → peor) por accuracy de test\")\n",
        "print(\"#\"*80)\n",
        "for i, r in enumerate(results_sorted, 1):\n",
        "    print(f\"{i}. {r['id']}: acc={r['final_test_acc']:.4f} | loss={r['final_test_loss']:.4f} | params={r['params']:,} | tiempo={r['elapsed_sec']:.1f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# # 4: Tuning de hiperparámetros (Random Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==========================================================================================\n",
            "Random Search - Trial 1/1  |  cfg: {'id': 'T01', 'hidden_layers': (512, 256), 'activation': np.str_('relu'), 'dropout': 0.2290550473839461, 'optimizer': np.str_('adam'), 'lr': 0.0004555636200065776, 'batch_size': 128, 'epochs': 10, 'weight_decay': 0.0}\n",
            "==========================================================================================\n",
            "[ T01 ] Epoch 01/10 | Train Loss: 0.3251 Acc: 0.9034 | Test  Loss: 0.1350 Acc: 0.9592\n",
            "[ T01 ] Epoch 02/10 | Train Loss: 0.1301 Acc: 0.9603 | Test  Loss: 0.0941 Acc: 0.9693\n",
            "[ T01 ] Epoch 03/10 | Train Loss: 0.0898 Acc: 0.9730 | Test  Loss: 0.0778 Acc: 0.9757\n",
            "[ T01 ] Epoch 04/10 | Train Loss: 0.0701 Acc: 0.9783 | Test  Loss: 0.0747 Acc: 0.9766\n",
            "[ T01 ] Epoch 05/10 | Train Loss: 0.0587 Acc: 0.9811 | Test  Loss: 0.0668 Acc: 0.9797\n",
            "[ T01 ] Epoch 06/10 | Train Loss: 0.0476 Acc: 0.9849 | Test  Loss: 0.0603 Acc: 0.9815\n",
            "[ T01 ] Epoch 07/10 | Train Loss: 0.0414 Acc: 0.9868 | Test  Loss: 0.0589 Acc: 0.9820\n",
            "[ T01 ] Epoch 08/10 | Train Loss: 0.0377 Acc: 0.9877 | Test  Loss: 0.0603 Acc: 0.9819\n",
            "[ T01 ] Epoch 09/10 | Train Loss: 0.0316 Acc: 0.9900 | Test  Loss: 0.0636 Acc: 0.9810\n",
            "[ T01 ] Epoch 10/10 | Train Loss: 0.0287 Acc: 0.9909 | Test  Loss: 0.0627 Acc: 0.9821\n",
            "\n",
            "##########################################################################################\n",
            "TOP-5 configuraciones por accuracy de test\n",
            "##########################################################################################\n",
            "1. T01 | acc=0.9821 | loss=0.0627 | params=535,818 | tiempo=137.0s | capas=(512, 256) act=relu do=0.23 opt=adam lr=0.00046 wd=0.0e+00 bs=128 ep=10\n",
            "\n",
            "Mejor configuración encontrada:\n",
            "{'id': 'T01', 'hidden_layers': (512, 256), 'activation': np.str_('relu'), 'dropout': 0.2290550473839461, 'optimizer': np.str_('adam'), 'lr': 0.0004555636200065776, 'batch_size': 128, 'epochs': 10, 'weight_decay': 0.0}\n",
            "Accuracy test: 0.9821  |  Loss test: 0.0627\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# --------- Espacios de búsqueda (podés ajustar) ---------\n",
        "HIDDEN_SPACE = [\n",
        "    (256,),\n",
        "    (384,),\n",
        "    (512,),\n",
        "    (512, 256),\n",
        "    (384, 192),\n",
        "    (512, 512, 256),\n",
        "]\n",
        "ACTIVATIONS = [\"relu\", \"tanh\", \"leakyrelu\"]\n",
        "OPTIMS = [\"adam\", \"adamw\"]\n",
        "BATCH_SIZES = [64, 96, 128, 192, 256]\n",
        "EPOCHS_RANGE = (6, 12)              # entero uniforme [6..12]\n",
        "DROPOUT_RANGE = (0.05, 0.35)        # continuo uniforme\n",
        "LR_RANGE = (1e-4, 3e-3)             # log-uniforme\n",
        "WD_RANGE = (1e-6, 3e-4)             # log-uniforme (si optim=adamw)\n",
        "\n",
        "def sample_log_uniform(low, high):\n",
        "    \"\"\"Muestrea en [low, high] con distribución log-uniforme.\"\"\"\n",
        "    return float(np.exp(np.random.uniform(np.log(low), np.log(high))))\n",
        "\n",
        "def sample_config(trial_id: int):\n",
        "    # Podés orientar la búsqueda “alrededor” de tu mejor config previa si querés\n",
        "    hidden_layers = HIDDEN_SPACE[np.random.randint(0, len(HIDDEN_SPACE))]\n",
        "    activation = np.random.choice(ACTIVATIONS)\n",
        "    optim = np.random.choice(OPTIMS)\n",
        "    batch_size = int(np.random.choice(BATCH_SIZES))\n",
        "    epochs = int(np.random.randint(EPOCHS_RANGE[0], EPOCHS_RANGE[1] + 1))\n",
        "    dropout = float(np.random.uniform(DROPOUT_RANGE[0], DROPOUT_RANGE[1]))\n",
        "    lr = sample_log_uniform(LR_RANGE[0], LR_RANGE[1])\n",
        "    weight_decay = sample_log_uniform(WD_RANGE[0], WD_RANGE[1]) if optim == \"adamw\" else 0.0\n",
        "\n",
        "    return {\n",
        "        \"id\": f\"T{trial_id:02d}\",\n",
        "        \"hidden_layers\": tuple(hidden_layers),\n",
        "        \"activation\": activation,\n",
        "        \"dropout\": dropout,\n",
        "        \"optimizer\": optim,\n",
        "        \"lr\": lr,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "        \"weight_decay\": weight_decay\n",
        "    }\n",
        "\n",
        "# --------- Runner de Random Search ---------\n",
        "def random_search(n_trials: int = 12, time_budget_sec: float = None):\n",
        "    \"\"\"\n",
        "    n_trials: cantidad de configuraciones a probar.\n",
        "    time_budget_sec: si querés cortar por tiempo total aprox. (opcional).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    t0 = time.time()\n",
        "\n",
        "    for t in range(1, n_trials + 1):\n",
        "        if time_budget_sec is not None and (time.time() - t0) > time_budget_sec:\n",
        "            print(\"\\nSe alcanzó el presupuesto de tiempo; se detiene la búsqueda.\")\n",
        "            break\n",
        "\n",
        "        cfg = sample_config(t)\n",
        "        print(\"\\n\" + \"=\"*90)\n",
        "        print(f\"Random Search - Trial {t}/{n_trials}  |  cfg: {cfg}\")\n",
        "        print(\"=\"*90)\n",
        "\n",
        "        try:\n",
        "            res = run_experiment(cfg)   # usa tu función definida en Parte 3\n",
        "            results.append(res)\n",
        "        except RuntimeError as e:\n",
        "            # Manejo simple por si hay OOM en GPU\n",
        "            if \"out of memory\" in str(e).lower():\n",
        "                print(\"OOM: saltando esta config. Probá reducir batch_size o capas.\")\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "    if not results:\n",
        "        print(\"No hay resultados. Revisá el espacio de búsqueda o errores en entrenamiento.\")\n",
        "        return []\n",
        "\n",
        "    # Ordenar por accuracy de test (desc)\n",
        "    results_sorted = sorted(results, key=lambda r: r[\"final_test_acc\"], reverse=True)\n",
        "\n",
        "    # Mostrar top-5\n",
        "    print(\"\\n\" + \"#\"*90)\n",
        "    print(\"TOP-5 configuraciones por accuracy de test\")\n",
        "    print(\"#\"*90)\n",
        "    for i, r in enumerate(results_sorted[:5], 1):\n",
        "        cfg = r[\"cfg\"]\n",
        "        print(f\"{i}. {r['id']} | acc={r['final_test_acc']:.4f} | loss={r['final_test_loss']:.4f} | \"\n",
        "              f\"params={r['params']:,} | tiempo={r['elapsed_sec']:.1f}s | \"\n",
        "              f\"capas={cfg['hidden_layers']} act={cfg['activation']} do={cfg['dropout']:.2f} \"\n",
        "              f\"opt={cfg['optimizer']} lr={cfg['lr']:.5f} wd={cfg['weight_decay']:.1e} \"\n",
        "              f\"bs={cfg['batch_size']} ep={cfg['epochs']}\")\n",
        "\n",
        "    best = results_sorted[0]\n",
        "    print(\"\\nMejor configuración encontrada:\")\n",
        "    print(best[\"cfg\"])\n",
        "    print(f\"Accuracy test: {best['final_test_acc']:.4f}  |  Loss test: {best['final_test_loss']:.4f}\")\n",
        "    return results_sorted\n",
        "\n",
        "# Ejecutar la búsqueda (ajustá n_trials según tu tiempo disponible)\n",
        "search_results = random_search(n_trials=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# # 5: Evaluación, comparación y ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def results_to_df(results):\n",
        "    rows = []\n",
        "    for r in results:\n",
        "        cfg = r[\"cfg\"]\n",
        "        rows.append({\n",
        "            \"id\": r[\"id\"],\n",
        "            \"test_acc\": r[\"final_test_acc\"],\n",
        "            \"test_loss\": r[\"final_test_loss\"],\n",
        "            \"params\": r[\"params\"],\n",
        "            \"time_s\": r[\"elapsed_sec\"],\n",
        "            \"layers\": cfg[\"hidden_layers\"],\n",
        "            \"activation\": cfg[\"activation\"],\n",
        "            \"dropout\": cfg[\"dropout\"],\n",
        "            \"optimizer\": cfg[\"optimizer\"],\n",
        "            \"lr\": cfg[\"lr\"],\n",
        "            \"weight_decay\": cfg[\"weight_decay\"],\n",
        "            \"batch_size\": cfg[\"batch_size\"],\n",
        "            \"epochs\": cfg[\"epochs\"],\n",
        "        })\n",
        "    df = pd.DataFrame(rows)\n",
        "    df = df.sort_values(\"test_acc\", ascending=False).reset_index(drop=True)\n",
        "    df.insert(0, \"rank\", df.index + 1)\n",
        "    return df\n",
        "\n",
        "df_models = results_to_df(results)  # 'results' viene de la Parte 3\n",
        "print(\"\\n=== Ranking (mejor → peor) por accuracy de test ===\")\n",
        "print(df_models[[\"rank\",\"id\",\"test_acc\",\"test_loss\",\"params\",\"time_s\",\"layers\",\"activation\",\"dropout\",\"optimizer\",\"lr\",\"weight_decay\",\"batch_size\",\"epochs\"]]\n",
        "      .to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
        "\n",
        "# Guardar a CSV (opcional)\n",
        "df_models.to_csv(\"mnist_mlp_ranking.csv\", index=False)\n",
        "print(\"\\nArchivo guardado: mnist_mlp_ranking.csv\")\n",
        "\n",
        "# Gráfico simple de accuracy por configuración (opcional)\n",
        "plt.figure()\n",
        "plt.bar(df_models[\"id\"], df_models[\"test_acc\"])\n",
        "plt.title(\"Accuracy de test por configuración\")\n",
        "plt.xlabel(\"Configuración\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0.90, 1.00)  # podés ajustar o comentar esta línea\n",
        "plt.show()\n",
        "\n",
        "# Si querés ver la curva de la mejor config:\n",
        "best_id = df_models.iloc[0][\"id\"]\n",
        "best_hist = next(r for r in results if r[\"id\"] == best_id)[\"history\"]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(best_hist[\"test_acc\"])\n",
        "plt.title(f\"Curva de accuracy (test) - {best_id}\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "AI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
