{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03b. Train YOLOv8 Detector (Transfer Learning)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ultralytics import YOLO\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model: yolov8n\n",
                        "Epochs: 20\n",
                        "Image Size: 640\n",
                        "Batch Size: 16\n"
                    ]
                }
            ],
            "source": [
                "# Paths\n",
                "DATA_YAML = '../data/yolo_dataset/data.yaml'\n",
                "MODEL_SAVE_DIR = '../models'\n",
                "\n",
                "# Training parameters\n",
                "EPOCHS = 20\n",
                "IMG_SIZE = 640\n",
                "BATCH_SIZE = 16  # Adjust based on your GPU memory\n",
                "MODEL_SIZE = 'yolov8n'  # Options: yolov8n (nano), yolov8s (small), yolov8m (medium)\n",
                "\n",
                "print(f'Model: {MODEL_SIZE}')\n",
                "print(f'Epochs: {EPOCHS}')\n",
                "print(f'Image Size: {IMG_SIZE}')\n",
                "print(f'Batch Size: {BATCH_SIZE}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Pre-trained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Loaded pre-trained yolov8n model\n",
                        "  This model was trained on COCO dataset (80 classes)\n",
                        "  We will fine-tune it for license plate detection (1 class)\n"
                    ]
                }
            ],
            "source": [
                "# Load pre-trained model\n",
                "model = YOLO(f'{MODEL_SIZE}.pt')\n",
                "\n",
                "print(f'Loaded pre-trained {MODEL_SIZE} model')\n",
                "print(f'  This model was trained on COCO dataset (80 classes)')\n",
                "print(f'  We will fine-tune it for license plate detection (1 class)')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Usando dispositivo: 0\n",
                        "Ultralytics 8.3.229  Python-3.11.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
                        "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_plate_detector11, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\runs\\detect\\yolo_plate_detector11, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
                        "Overriding model.yaml nc=80 with nc=1\n",
                        "\n",
                        "                   from  n    params  module                                       arguments                     \n",
                        "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
                        "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
                        "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
                        "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
                        "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
                        "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
                        "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
                        "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
                        "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
                        "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
                        " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
                        " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
                        " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
                        " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
                        " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
                        " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
                        " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
                        " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
                        " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
                        " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
                        "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
                        "\n",
                        "Transferred 319/355 items from pretrained weights\n",
                        "Freezing layer 'model.22.dfl.conv.weight'\n",
                        "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
                        "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1028.91751.0 MB/s, size: 134.3 KB)\n",
                        "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\labels\\train... 1313 images, 0 backgrounds, 11 corrupt: 100% ━━━━━━━━━━━━ 1324/1324 1.6Kit/s 0.8s0.0s\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars103.png: ignoring corrupt image/label: image size (5, 20) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars132.png: ignoring corrupt image/label: image size (8, 39) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars139.png: ignoring corrupt image/label: image size (8, 26) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars146.png: ignoring corrupt image/label: image size (8, 31) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars188.png: ignoring corrupt image/label: image size (9, 13) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars249.png: ignoring corrupt image/label: image size (8, 37) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars277.png: ignoring corrupt image/label: image size (7, 28) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars350.png: ignoring corrupt image/label: image size (9, 57) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars362.png: ignoring corrupt image/label: image size (7, 27) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars71.png: ignoring corrupt image/label: image size (8, 36) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\images\\train\\zoom_Cars75.png: ignoring corrupt image/label: image size (5, 9) <10 pixels\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\labels\\train.cache\n",
                        "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 608.7829.6 MB/s, size: 148.1 KB)\n",
                        "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\labels\\val... 166 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 166/166 424.3it/s 0.4s0.2s\n",
                        "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\labels\\val.cache\n",
                        "Plotting labels to C:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\runs\\detect\\yolo_plate_detector11\\labels.jpg... \n",
                        "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
                        "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
                        "Image sizes 640 train, 640 val\n",
                        "Using 8 dataloader workers\n",
                        "Logging results to \u001b[1mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\runs\\detect\\yolo_plate_detector11\u001b[0m\n",
                        "Starting training for 20 epochs...\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K       1/20      2.09G      1.055      1.765       1.27          3        640: 100% ━━━━━━━━━━━━ 83/83 6.7it/s 12.4s0.1s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 6.6it/s 0.9s0.2s\n",
                        "                   all        166        166      0.557      0.319      0.427      0.236\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K       2/20       2.1G     0.9585      1.122      1.156          3        640: 100% ━━━━━━━━━━━━ 83/83 8.4it/s 9.9s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 8.9it/s 0.7s0.2s\n",
                        "                   all        166        166      0.518      0.524      0.402        0.2\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K       3/20       2.1G      1.013      1.002       1.19          4        640: 100% ━━━━━━━━━━━━ 83/83 8.8it/s 9.5s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 10.0it/s 0.6s.2s\n",
                        "                   all        166        166      0.661      0.727      0.663      0.368\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K       4/20       2.1G     0.9306     0.8447       1.16          2        640: 100% ━━━━━━━━━━━━ 83/83 8.8it/s 9.5s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.5it/s 0.6s0.1s\n",
                        "                   all        166        166      0.861      0.705      0.856      0.474\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K       5/20       2.1G     0.8794     0.7536      1.116          4        640: 100% ━━━━━━━━━━━━ 83/83 8.8it/s 9.5s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.5it/s 0.6s0.1s\n",
                        "                   all        166        166       0.85      0.785      0.859      0.471\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K       6/20       2.1G     0.8844     0.7323      1.124          1        640: 100% ━━━━━━━━━━━━ 83/83 8.7it/s 9.5s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.3it/s 0.6s0.1s\n",
                        "                   all        166        166      0.916      0.853      0.905      0.532\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K       7/20       2.1G     0.8086     0.6215      1.087          3        640: 100% ━━━━━━━━━━━━ 83/83 8.5it/s 9.7s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.2it/s 0.7s0.1s\n",
                        "                   all        166        166      0.805      0.886      0.887      0.516\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K       8/20       2.1G     0.7896     0.6002      1.071          4        640: 100% ━━━━━━━━━━━━ 83/83 8.8it/s 9.5s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.3it/s 0.6s0.1s\n",
                        "                   all        166        166      0.829      0.867      0.877      0.508\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K       9/20       2.1G     0.7722     0.6095      1.062          1        640: 100% ━━━━━━━━━━━━ 83/83 8.6it/s 9.6s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.3it/s 0.6s0.1s\n",
                        "                   all        166        166      0.896      0.873      0.927      0.555\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      10/20       2.1G     0.7672      0.552      1.067          1        640: 100% ━━━━━━━━━━━━ 83/83 8.6it/s 9.6s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.5it/s 0.6s0.1s\n",
                        "                   all        166        166      0.883      0.911      0.946      0.573\n",
                        "Closing dataloader mosaic\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      11/20       2.1G     0.8036     0.6628      1.113          1        640: 100% ━━━━━━━━━━━━ 83/83 8.2it/s 10.1s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 8.8it/s 0.7s0.2s\n",
                        "                   all        166        166      0.882      0.855      0.927      0.545\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      12/20       2.1G     0.7836     0.6078       1.08          1        640: 100% ━━━━━━━━━━━━ 83/83 8.6it/s 9.6s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.2it/s 0.7s0.1s\n",
                        "                   all        166        166      0.951      0.861      0.953      0.582\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      13/20       2.1G     0.7463     0.5226      1.072          1        640: 100% ━━━━━━━━━━━━ 83/83 8.7it/s 9.5s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.9it/s 0.6s0.2s\n",
                        "                   all        166        166      0.955      0.855      0.966      0.615\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      14/20       2.1G      0.746     0.5055      1.096          1        640: 100% ━━━━━━━━━━━━ 83/83 8.7it/s 9.5s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.8it/s 0.6s0.2s\n",
                        "                   all        166        166      0.924      0.898      0.961      0.603\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      15/20       2.1G     0.6997     0.4825      1.041          1        640: 100% ━━━━━━━━━━━━ 83/83 8.7it/s 9.5s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.7it/s 0.6s0.1s\n",
                        "                   all        166        166      0.928      0.922      0.967      0.619\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      16/20       2.1G      0.679       0.45      1.031          1        640: 100% ━━━━━━━━━━━━ 83/83 8.7it/s 9.5s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.7it/s 0.6s0.1s\n",
                        "                   all        166        166      0.936      0.922       0.97      0.635\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      17/20       2.1G      0.659     0.4344      1.022          1        640: 100% ━━━━━━━━━━━━ 83/83 8.8it/s 9.4s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 10.0it/s 0.6s.2s\n",
                        "                   all        166        166      0.948       0.91      0.968      0.635\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      18/20       2.1G     0.6358     0.4017      1.008          1        640: 100% ━━━━━━━━━━━━ 83/83 8.8it/s 9.4s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.3it/s 0.6s0.2s\n",
                        "                   all        166        166      0.964      0.916       0.97      0.633\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      19/20       2.1G     0.6225     0.3892     0.9996          1        640: 100% ━━━━━━━━━━━━ 83/83 8.8it/s 9.4s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.3it/s 0.6s0.1s\n",
                        "                   all        166        166      0.958      0.928      0.979      0.645\n",
                        "\n",
                        "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
                        "\u001b[K      20/20       2.1G     0.5947     0.3742     0.9866          1        640: 100% ━━━━━━━━━━━━ 83/83 8.9it/s 9.4s0.2s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 9.5it/s 0.6s0.1s\n",
                        "                   all        166        166      0.957      0.931      0.981      0.653\n",
                        "\n",
                        "20 epochs completed in 0.064 hours.\n",
                        "Optimizer stripped from C:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\runs\\detect\\yolo_plate_detector11\\weights\\last.pt, 6.2MB\n",
                        "Optimizer stripped from C:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\runs\\detect\\yolo_plate_detector11\\weights\\best.pt, 6.2MB\n",
                        "\n",
                        "Validating C:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\runs\\detect\\yolo_plate_detector11\\weights\\best.pt...\n",
                        "Ultralytics 8.3.229  Python-3.11.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
                        "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 6.9it/s 0.9s0.2s\n",
                        "                   all        166        166      0.957      0.931      0.981      0.653\n",
                        "Speed: 0.1ms preprocess, 1.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
                        "Results saved to \u001b[1mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\runs\\detect\\yolo_plate_detector11\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "DEVICE = 0 if torch.cuda.is_available() else 'cpu'\n",
                "print('Usando dispositivo:', DEVICE)\n",
                "\n",
                "results = model.train(\n",
                "    data=DATA_YAML,\n",
                "    epochs=EPOCHS,\n",
                "    imgsz=IMG_SIZE,\n",
                "    batch=BATCH_SIZE,\n",
                "    name='yolo_plate_detector',\n",
                "    patience=10,\n",
                "    save=True,\n",
                "    device=DEVICE,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluate the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ultralytics 8.3.229  Python-3.11.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
                        "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1240.0492.5 MB/s, size: 353.6 KB)\n",
                        "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\data\\yolo_dataset\\labels\\val.cache... 166 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 166/166  0.0s\n",
                        "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 8.8it/s 1.2s<0.1s\n",
                        "                   all        166        166      0.956      0.924      0.981      0.657\n",
                        "Speed: 0.8ms preprocess, 3.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
                        "Results saved to \u001b[1mC:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\runs\\detect\\val5\u001b[0m\n",
                        "\n",
                        "========================================\n",
                        "       RESULTADOS DE VALIDACIÓN\n",
                        "========================================\n",
                        "| Métrica                     |   Valor | Target (Meta)   |\n",
                        "|:----------------------------|--------:|:----------------|\n",
                        "| mAP@0.5 (Precisión IoU 0.5) |  0.9810 | > 0.90          |\n",
                        "| mAP@0.5:0.95 (Robustez)     |  0.6571 | > 0.60          |\n",
                        "| Precision (Exactitud)       |  0.9564 | > 0.90          |\n",
                        "| Recall (Sensibilidad)       |  0.9243 | > 0.90          |\n",
                        "\n",
                        "Gráfica guardada en reports/images/yolo_metrics.png\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 1000x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "\n",
                "# 1. Obtener las métricas del modelo\n",
                "metrics = model.val(verbose=False)\n",
                "\n",
                "# 2. Organizar los datos\n",
                "data = {\n",
                "    \"Métrica\": [\"mAP@0.5 (Precisión IoU 0.5)\", \"mAP@0.5:0.95 (Robustez)\", \"Precision (Exactitud)\", \"Recall (Sensibilidad)\"],\n",
                "    \"Valor\": [metrics.box.map50, metrics.box.map, metrics.box.mp, metrics.box.mr],\n",
                "    \"Target (Meta)\": [\"> 0.90\", \"> 0.60\", \"> 0.90\", \"> 0.90\"]\n",
                "}\n",
                "\n",
                "df_metrics = pd.DataFrame(data)\n",
                "\n",
                "# --- OPCIÓN A: TABLA LIMPIA PARA EL NOTEBOOK ---\n",
                "print(\"\\n\" + \"=\"*40)\n",
                "print(\"       RESULTADOS DE VALIDACIÓN\")\n",
                "print(\"=\"*40)\n",
                "# Formatear valores a 4 decimales\n",
                "print(df_metrics.to_markdown(index=False, floatfmt=\".4f\"))\n",
                "\n",
                "\n",
                "# --- OPCIÓN B: GRÁFICA PARA LA PRESENTACIÓN ---\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.set_style(\"whitegrid\")\n",
                "\n",
                "# Crear gráfico de barras\n",
                "ax = sns.barplot(x=\"Valor\", y=\"Métrica\", data=df_metrics, palette=\"viridis\")\n",
                "\n",
                "# Línea de referencia de perfección (1.0)\n",
                "plt.axvline(1.0, color='gray', linestyle='--', alpha=0.5)\n",
                "plt.xlim(0, 1.1)\n",
                "\n",
                "# Añadir los valores numéricos al lado de las barras\n",
                "for i, v in enumerate(df_metrics[\"Valor\"]):\n",
                "    ax.text(v + 0.02, i, f\"{v:.4f}\", color='black', fontweight='bold', va='center')\n",
                "\n",
                "plt.title(\"Rendimiento del Detector YOLOv8 (Validation Set)\", fontsize=15, fontweight='bold')\n",
                "plt.xlabel(\"Puntuación (0.0 - 1.0)\", fontsize=12)\n",
                "plt.ylabel(\"\")\n",
                "\n",
                "# Guardar para el reporte\n",
                "plt.tight_layout()\n",
                "plt.savefig('../reports/images/yolo_metrics.png', dpi=300)\n",
                "print(\"\\nGráfica guardada en reports/images/yolo_metrics.png\")\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save the Best Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "best.pt no encontrado en: runs\\detect\\yolo_plate_detector9\\weights\\best.pt\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import shutil\n",
                "\n",
                "# Carpeta donde YOLO guarda los runs\n",
                "runs_dir = os.path.join('runs', 'detect')\n",
                "exp_prefix = 'yolo_plate_detector'\n",
                "\n",
                "# Buscar todas las carpetas que empiezan por 'yolo_plate_detector'\n",
                "run_dirs = []\n",
                "if os.path.exists(runs_dir):\n",
                "    run_dirs = [d for d in os.listdir(runs_dir)\n",
                "                if d.startswith(exp_prefix) and os.path.isdir(os.path.join(runs_dir, d))]\n",
                "\n",
                "if not run_dirs:\n",
                "    print(f'No se encontraron runs en {runs_dir} con prefijo \"{exp_prefix}\"')\n",
                "else:\n",
                "    # Usar el último run (ordenado alfabéticamente: yolo_plate_detector, yolo_plate_detector2, ...7)\n",
                "    last_run = sorted(run_dirs)[-1]\n",
                "    best_model_path = os.path.join(runs_dir, last_run, 'weights', 'best.pt')\n",
                "    destination = os.path.join(MODEL_SAVE_DIR, 'yolo_plate_detector.pt')\n",
                "\n",
                "    if os.path.exists(best_model_path):\n",
                "        os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
                "        shutil.copy(best_model_path, destination)\n",
                "        print(f'Best model ({last_run}) saved to: {destination}')\n",
                "    else:\n",
                "        print(f'best.pt no encontrado en: {best_model_path}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test on Sample Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "image 1/1 c:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\..\\data\\yolo_dataset\\images\\val\\Cars10.png: 384x640 1 license_plate, 34.7ms\n",
                        "Speed: 1.9ms preprocess, 34.7ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
                        "\n",
                        "image 1/1 c:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\..\\data\\yolo_dataset\\images\\val\\Cars102.png: 512x640 1 license_plate, 31.5ms\n",
                        "Speed: 1.9ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
                        "\n",
                        "image 1/1 c:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\..\\data\\yolo_dataset\\images\\val\\Cars104.png: 480x640 1 license_plate, 32.1ms\n",
                        "Speed: 1.2ms preprocess, 32.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
                        "\n",
                        "image 1/1 c:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\..\\data\\yolo_dataset\\images\\val\\Cars107.png: 384x640 1 license_plate, 5.8ms\n",
                        "Speed: 1.4ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
                        "\n",
                        "image 1/1 c:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\..\\data\\yolo_dataset\\images\\val\\Cars119.png: 416x640 1 license_plate, 30.7ms\n",
                        "Speed: 0.9ms preprocess, 30.7ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
                        "\n",
                        "image 1/1 c:\\Users\\Paco\\Documents\\github\\Inteligencia_artificial\\ProyectoFinal\\notebooks\\..\\data\\yolo_dataset\\images\\val\\Cars124.png: 448x640 3 license_plates, 30.7ms\n",
                        "Speed: 1.3ms preprocess, 30.7ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 1500x1000 with 6 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import cv2\n",
                "import numpy as np\n",
                "\n",
                "# Load the best model\n",
                "best_model = YOLO(destination)\n",
                "\n",
                "# Test on validation images\n",
                "test_dir = '../data/yolo_dataset/images/val'\n",
                "test_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir)[:6]]\n",
                "\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, img_path in enumerate(test_images):\n",
                "    # Predict\n",
                "    results = best_model(img_path)\n",
                "    \n",
                "    # Get annotated image\n",
                "    annotated = results[0].plot()\n",
                "    annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    axes[i].imshow(annotated)\n",
                "    axes[i].set_title(os.path.basename(img_path))\n",
                "    axes[i].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## View Training Curves\n",
                "\n",
                "Check `runs/detect/yolo_plate_detector/` for:\n",
                "- `results.png` - Training/validation metrics\n",
                "- `confusion_matrix.png` - Confusion matrix\n",
                "- `val_batch*_pred.jpg` - Validation predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Results image not found en: runs\\detect\\yolo_plate_detector9\\results.png\n"
                    ]
                }
            ],
            "source": [
                "from IPython.display import Image, display\n",
                "import os\n",
                "\n",
                "runs_dir = os.path.join('runs', 'detect')\n",
                "exp_prefix = 'yolo_plate_detector'\n",
                "\n",
                "# Buscar runs que empiezan por yolo_plate_detector\n",
                "run_dirs = []\n",
                "if os.path.exists(runs_dir):\n",
                "    run_dirs = [d for d in os.listdir(runs_dir)\n",
                "                if d.startswith(exp_prefix) and os.path.isdir(os.path.join(runs_dir, d))]\n",
                "\n",
                "if not run_dirs:\n",
                "    print(f'No se encontraron runs en {runs_dir} con prefijo \"{exp_prefix}\"')\n",
                "else:\n",
                "    last_run = sorted(run_dirs)[-1]  # p.ej. yolo_plate_detector7\n",
                "    results_img = os.path.join(runs_dir, last_run, 'results.png')\n",
                "    if os.path.exists(results_img):\n",
                "        display(Image(filename=results_img))\n",
                "        print(f'Mostrando: {results_img}')\n",
                "    else:\n",
                "        print(f'Results image not found en: {results_img}')\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "anpr-gpu",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
